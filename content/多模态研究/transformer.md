---
title: "Transformer"
subtitle: ""
date: 2025-04-03T10:06:42+08:00
description: ""
keywords: ""
comment: false
---

## Attention(注意力机制)
对于一堆数据，我们想使用重要的数据，不使用不重要的数据，但是对一个模型而言它很难决定哪些重要，哪些不重要。

> 注意力机制就是把注意力聚焦在比较重要的事物上

## 一些概念QKV
 
