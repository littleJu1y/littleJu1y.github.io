<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/WebPage" lang="en">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
    <meta name="robots" content="noodp" />
    <title>Transformer - July Blog</title><meta name="author" content="July">
<meta name="description" content="transformer 方法来自于论文《Attention is All You Need》,之前看b站的各种视频讲解总是一知半解，现在希望可以通过阅读原始论文弄懂。
"><meta name="keywords" content='Hugo, FixIt'>
  <meta itemprop="name" content="Transformer">
  <meta itemprop="description" content="transformer 方法来自于论文《Attention is All You Need》,之前看b站的各种视频讲解总是一知半解，现在希望可以通过阅读原始论文弄懂。">
  <meta itemprop="datePublished" content="2025-04-03T10:06:42+08:00">
  <meta itemprop="dateModified" content="2025-06-12T16:13:36+08:00">
  <meta itemprop="wordCount" content="1591"><meta property="og:url" content="http://localhost:1313/%E5%A4%9A%E6%A8%A1%E6%80%81%E7%A0%94%E7%A9%B6/transformer/">
  <meta property="og:site_name" content="July Blog">
  <meta property="og:title" content="Transformer">
  <meta property="og:description" content="transformer 方法来自于论文《Attention is All You Need》,之前看b站的各种视频讲解总是一知半解，现在希望可以通过阅读原始论文弄懂。">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="多模态研究">
    <meta property="article:published_time" content="2025-04-03T10:06:42+08:00">
    <meta property="article:modified_time" content="2025-06-12T16:13:36+08:00">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Transformer">
  <meta name="twitter:description" content="transformer 方法来自于论文《Attention is All You Need》,之前看b站的各种视频讲解总是一知半解，现在希望可以通过阅读原始论文弄懂。">
<meta name="application-name" content="Hugo FixIt Blog">
<meta name="apple-mobile-web-app-title" content="Hugo FixIt Blog"><meta name="theme-color" data-light="#f8f8f8" data-dark="#252627" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="canonical" type="text/html" href="http://localhost:1313/%E5%A4%9A%E6%A8%A1%E6%80%81%E7%A0%94%E7%A9%B6/transformer/" title="Transformer - July Blog" /><link rel="prev" type="text/html" href="http://localhost:1313/%E5%A4%9A%E6%A8%A1%E6%80%81%E7%A0%94%E7%A9%B6/%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E6%96%B9%E6%B3%95/" title="特征融合方法" /><link rel="next" type="text/html" href="http://localhost:1313/%E5%A4%9A%E6%A8%A1%E6%80%81%E7%A0%94%E7%A9%B6/%E7%BB%BC%E8%BF%B0/" title="综述" /><link rel="alternate" type="text/markdown" href="http://localhost:1313/%E5%A4%9A%E6%A8%A1%E6%80%81%E7%A0%94%E7%A9%B6/transformer/index.md" title="Transformer - July Blog"><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="/lib/fontawesome-free/all.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"></noscript><link rel="preload" href="/lib/animate/animate.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/lib/animate/animate.min.css"></noscript><script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "headline": "Transformer",
    "inLanguage": "en",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "http:\/\/localhost:1313\/%E5%A4%9A%E6%A8%A1%E6%80%81%E7%A0%94%E7%A9%B6\/transformer\/"
    },"genre": "多模态研究","wordcount":  1591 ,
    "url": "http:\/\/localhost:1313\/%E5%A4%9A%E6%A8%A1%E6%80%81%E7%A0%94%E7%A9%B6\/transformer\/","datePublished": "2025-04-03T10:06:42+08:00","dateModified": "2025-06-12T16:13:36+08:00","publisher": {
      "@type": "Organization",
      "name": ""},"author": {
        "@type": "Person",
        "name": "July"
      },"description": ""
  }
  </script><script src="/js/head/color-scheme.min.js"></script></head>
  <body data-header-desktop="sticky" data-header-mobile="auto"><div class="wrapper" data-page-style="normal"><header class="desktop animate__faster" id="header-desktop">
  <div class="header-wrapper">
    <div class="header-title">
      <a href="/" title="July Blog"><img class="logo" src='/images/pika.svg' alt="July Blog" height="32" width="32"><span class="header-title-text">July Blog</span></a><span class="header-subtitle"></span></div>
    <nav>
      <ul class="menu"><li class="menu-item">
              <a class="menu-link" href="/archives/"><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> Archives</a></li><li class="menu-item">
              <a class="menu-link" href="/categories/"><i class="fa-solid fa-folder-tree fa-fw fa-sm" aria-hidden="true"></i> Categories</a></li><li class="menu-item">
              <a class="menu-link" href="/tags/"><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> Tags</a></li><li class="menu-item delimiter"></li><li class="menu-item search" id="search-desktop">
            <input type="text" placeholder="Search titles or contents ..." id="search-input-desktop">
            <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
              <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
            </a>
            <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
              <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
            </a>
            <span class="search-button search-loading" id="search-loading-desktop">
              <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
            </span>
          </li><li class="menu-item theme-switch" title="Switch Theme">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li></ul>
    </nav>
  </div>
</header><header class="mobile animate__faster" id="header-mobile">
  <div class="header-container">
    <div class="header-wrapper">
      <div class="header-title">
        <a href="/" title="July Blog"><img class="logo" src='/images/pika.svg' alt="July Blog" height="26" width="26"><span class="header-title-text">July Blog</span></a><span class="header-subtitle"></span></div>
      <div class="menu-toggle" id="menu-toggle-mobile">
        <span></span><span></span><span></span>
      </div>
    </div>
    <nav>
      <ul class="menu" id="menu-mobile"><li class="search-wrapper">
            <div class="search mobile" id="search-mobile">
              <input type="text" placeholder="Search titles or contents ..." id="search-input-mobile">
              <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
              </a>
              <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
              </a>
              <span class="search-button search-loading" id="search-loading-mobile">
                <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
              </span>
            </div>
            <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
              Cancel
            </a>
          </li><li class="menu-item"><a class="menu-link" href="/archives/"><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> Archives</a></li><li class="menu-item"><a class="menu-link" href="/categories/"><i class="fa-solid fa-folder-tree fa-fw fa-sm" aria-hidden="true"></i> Categories</a></li><li class="menu-item"><a class="menu-link" href="/tags/"><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> Tags</a></li><li class="menu-item menu-system">
          <span class="menu-system-item theme-switch" title="Switch Theme"><i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i></span></li>
      </ul>
    </nav>
  </div>
</header><div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
  </div>
  <div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
  </div><main class="container"><article class="page single special">
    <div class="header"><h1 class="single-title animate__animated animate__pulse animate__faster">Transformer</h1></div><div class="content" id="content"><h2 class="heading-element" id="transformer"><span>transformer</span>
  <a href="#transformer" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><p>方法来自于论文《Attention is All You Need》,之前看b站的各种视频讲解总是一知半解，现在希望可以通过阅读原始论文弄懂。</p>
<h2 class="heading-element" id="abstract"><span>abstract</span>
  <a href="#abstract" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><p>首先让我们阅读文章的摘要。
<img loading="lazy" src='/pic/transformer/%E6%91%98%E8%A6%81.png' alt="摘要" height="622" width="1066"></p>
<p>摘要提到之前的主流序列转导模型主要是rnn，使用编码器-解码器结构，使用注意力机制进行增强。而作者提出了一种新的简单的网络架构名为&quot;transformer&quot;，而这种架构有三个特点：</p>
<ol>
<li>完全摒弃了RNN/CNN</li>
<li>仍然使用编码器-解码器结构</li>
<li>完全基于注意力机制</li>
</ol>
<h2 class="heading-element" id="backgroud其中的rnn与编码器-解码器结构"><span>backgroud其中的RNN与编码器-解码器结构</span>
  <a href="#backgroud%e5%85%b6%e4%b8%ad%e7%9a%84rnn%e4%b8%8e%e7%bc%96%e7%a0%81%e5%99%a8-%e8%a7%a3%e7%a0%81%e5%99%a8%e7%bb%93%e6%9e%84" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><p><img loading="lazy" src='/pic/transformer/rnn.png' alt="RNN" height="897" width="1626">
经典的RNN结构，这里不再赘述，简单理解便是上一个token的计算结果会作为第二个token的输入来参与计算。不过RNN有很多缺陷，比如输入和输出不等长。</p>
<p><img loading="lazy" src='/pic/transformer/%E7%BC%96%E7%A0%81%E5%99%A8-%E8%A7%A3%E7%A0%81%E5%99%A8.png' alt="编码器-解码器" height="507" width="904">
编码器-解码器结构可以理解为将RNN的上半部分和下半部分拆开，编码器去掉了RNN上半部分y的输出，只保留隐藏状态h，中间向量C（上下文向量）是对整个输入序列的语义编码，是一个固定长度的向量，涵盖了整个输出文本的语义信息。</p>
<p>不过编码器-解码器也有很多问题：</p>
<ol>
<li>语义的稀释问题，随着序列长度的增长，远距离依赖信息在传递过程中很容易被稀释，导致模型对长距离依赖关系的建模能力减弱。</li>
<li>不同token对结果的重要性应该是不一样的，但是这个结构无法体现。</li>
</ol>
<blockquote>
<p>注意注意力机制在之前就已经提出过，该论文是提出了自注意力机制。</p></blockquote>
<p><a href="/pic/transformer/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6.png">!注意力机制</a>
最简单的注意力机制其实就是一个权重的分配，每一个输出的输入是通过加权平均得到的。</p>
<h2 class="heading-element" id="模型架构"><span>模型架构</span>
  <a href="#%e6%a8%a1%e5%9e%8b%e6%9e%b6%e6%9e%84" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><p><a href="/pic/transformer/%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84.png">!模型架构</a></p>
<p>要理解transformer的架构设计，要理解该架构解决的问题：串行计算。对于文本“我爱水课”来说，假设编码“水”这个token，在之前必须要先等“我爱”编码完，但是实际上机器学习的训练我们是有答案的，“我爱水课”与“I love easy courses”我们事先都是知道的，所以实际上没有必要去等待。我们不让他们再去等待，而是采用另一种编码-解码方式。</p>
<p>在编码的时候，首先每一个词都会被转换为一个向量，在transformer中，该向量为512维，假设在编码“水”的时候，可以以全局的视角看到上下文所有的信息，然后将这些信息编码到向量中，而且这个过程是可以并行进行的。（解码同理）</p>
<p>模型架构的左边是编码器，右边是解码器。具体的流程如下：</p>
<ol>
<li>对于“我爱水课”这句话，首先将每个词转换为512维的向量（词嵌入embedding），“水”和“瀑布”可能被映射到很近的向量空间。词嵌入有不同的方式，词嵌入模型可以一起去训练，你也可以用别人训练好的词嵌入模型。</li>
<li>位置编码。通过显式的编码将位置信息带进去。给每一个词生成一个512维的位置向量（具体是通过余弦向量），然后将位置向量直接叠加到原本的语义信息中。</li>
<li>单头注意力。主要是为了处理上下文编码（橙色模块），先讲单头注意力，有三个矩阵wq，wk，wv，每一个矩阵都是512×512的矩阵。假设“水”这个词，这个向量分别×wq，wv，wk，1×512 × 515×512 = 1 × 512，所以得到三个1×512，注意这三个矩阵是在训练过程中得到的（非常重要的参数）。每一个词都会得到三个矩阵，q是qurey，k是key，v是value。“我爱水课”和“西瓜是我最爱的水果”其中的水应该是不一样的，它的偏移应该不一样，对于qkv来说，可以理解为一个词的q是在发问：是否有名词？k则是在回答：我是不是名词，而v则是该名词的值。计算公式如下：</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-latex" data-lang="latex"><span class="line"><span class="cl">Attention(Q,K,V)=softmax(<span class="k">\frac</span><span class="nb">{</span>Qk<span class="nb">^</span>T<span class="nb">}{</span><span class="k">\sqrt</span><span class="nb">{</span>d<span class="nb">_{</span>k<span class="nb">}</span> <span class="nb">}</span> <span class="nb">}</span> )V</span></span></code></pre></td></tr></table>
</div>
</div><p>Q与K做点积，以水为例，Q水×（K我，k爱，k水，k课）得到的结果理解为水向每一个token发问，拿到结果，如果目标是名词的话，那么这个值就会越大，这个权重实际上就是一个相似度分数，然后再做一个缩放便于模型训练，再经过softmax，得到的含义就是当前所有词对水这个词语义影响的重要程度，然后再与v做矩阵乘法便得到了全新的信息向量。</p>
<ol start="4">
<li>多头注意力机制。实际上transformer使用的是多头注意力机制，</li>
</ol>
</div></article></main><footer class="footer">
    <div class="footer-container"><div class="footer-line powered">Powered by <a href="https://gohugo.io/" target="_blank" rel="external nofollow noopener noreferrer" title="Hugo 0.147.2"><img class="hugo-icon" src="/images/hugo.min.svg" alt="Hugo logo" /> Hugo</a> | Theme - <a href="https://github.com/hugo-fixit/FixIt" target="_blank" rel="external" title="FixIt v0.3.21-a85a6655"><img class="fixit-icon" src="/images/fixit.min.svg" alt="FixIt logo" /> FixIt</a>
        </div><div class="footer-line copyright" itemscope itemtype="http://schema.org/CreativeWork"><i class="fa-regular fa-copyright fa-fw" aria-hidden="true"></i>
            <span itemprop="copyrightYear">2025</span><span class="author" itemprop="copyrightHolder">
              <a href="/">July</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a></span></div></div>
  </footer></div><div class="widgets"><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role="button" aria-label="Back to Top"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden="true"></i><span class="variant-numeric d-none">0%</span>
        </div></div><div id="mask"></div><noscript>
    <div class="noscript-warning">This website works best with JavaScript enabled.</div>
  </noscript>
</div><link rel="preload" href="/lib/katex/katex.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/lib/katex/katex.min.css"></noscript><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><script src="/lib/autocomplete/autocomplete.min.js" defer></script><script src="/lib/fuse/fuse.min.js" defer></script><script src="/lib/sharer/sharer.min.js" async defer></script><script src="/lib/katex/katex.min.js" defer></script><script src="/lib/katex/auto-render.min.js" defer></script><script src="/lib/katex/copy-tex.min.js" defer></script><script src="/lib/katex/mhchem.min.js" defer></script><script src="/lib/cookieconsent/cookieconsent.min.js" defer></script><script>window.config={"code":{"copyTitle":"Copy to clipboard","editLockTitle":"Lock editable code block","editUnLockTitle":"Unlock editable code block","editable":true,"maxShownLines":10},"comment":{"enable":false},"cookieconsent":{"content":{"dismiss":"Got it!","link":"Learn more","message":"This website uses Cookies to improve your experience."},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"distance":100,"findAllMatches":false,"fuseIndexURL":"/search.json","highlightTag":"em","ignoreFieldNorm":false,"ignoreLocation":false,"isCaseSensitive":false,"location":0,"maxResultLength":10,"minMatchCharLength":2,"noResultsFound":"No results found","snippetLength":30,"threshold":0.3,"type":"fuse","useExtendedSearch":false},"version":"v0.3.21-a85a6655"};console.log('Page config:', window.config);</script><script src="/js/theme.min.js" defer></script><script src="/js/custom.min.js" defer></script></body>
</html>
