# Transformer


## Attention(注意力机制)
对于一堆数据，我们想使用重要的数据，不使用不重要的数据，但是对一个模型而言它很难决定哪些重要，哪些不重要。

> 注意力机制就是把注意力聚焦在比较重要的事物上

## 一些概念QKV
 


---

> Author: <no value>  
> URL: https://littleju1y.github.io/%E5%A4%9A%E6%A8%A1%E6%80%81%E7%A0%94%E7%A9%B6/transformer/  

